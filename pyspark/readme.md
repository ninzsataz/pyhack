# Resources for using pyspark
About **Spark**: 
- Spark is a generic engine for processing large amounts of data
- Spark is written in Scala and runs on the java virtual machine (JVM)

**PySpark** allows you to access Spark's functionality. Think of it as:
- a python-based wrapper on top of the Scala API
- a library that allows processing large amounts of data on a single machine or a cluster of machines
- a way to handle parallel processing without the need for the threading or multiprocessing modules

